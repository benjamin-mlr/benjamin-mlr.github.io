[{"authors":["admin"],"categories":null,"content":"I am a third-year PhD student at Sorbonne Université and INRIA Paris in the Almanach research team. My research focuses on understanding the behavior of large scale language models and applying them efficiently in the multilingual context. I have interned at Apple AI/ML and Amazon Alexa AI. I am also the main instructor for the Machine Learning for NLP course at ENSAE Paris.\n","date":1655856000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1655856000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ben-mlr.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a third-year PhD student at Sorbonne Université and INRIA Paris in the Almanach research team. My research focuses on understanding the behavior of large scale language models and applying them efficiently in the multilingual context. I have interned at Apple AI/ML and Amazon Alexa AI. I am also the main instructor for the Machine Learning for NLP course at ENSAE Paris.","tags":null,"title":"Benjamin Muller","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c8e7cea3e6b2ac48c9d20082dcfc742d","permalink":"https://ben-mlr.github.io/post/slider/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/slider/","section":"post","summary":"","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"The Best Way to Create the Website You Want from Markdown (or Jupyter/RStudio)\nBuild Anything with Widgets\nStar","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"85a8569f55c6c2086c14e785ef623151","permalink":"https://ben-mlr.github.io/post/hero/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/hero/","section":"post","summary":"The Best Way to Create the Website You Want from Markdown (or Jupyter/RStudio)\nBuild Anything with Widgets","tags":null,"title":"Academic","type":"post"},{"authors":null,"categories":null,"content":"Welcome to the Academic Kickstart template!\nFollow our Getting Started and Page Builder guides to easily personalize the template and then add your own content.\nFor inspiration, check out the Markdown files which power the personal demo. The easiest way to publish your new site to the internet is with Netlify.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"523ab7169205f7529d3846704dedf859","permalink":"https://ben-mlr.github.io/post/demo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/demo/","section":"post","summary":"Welcome to the Academic Kickstart template!\nFollow our Getting Started and Page Builder guides to easily personalize the template and then add your own content.\nFor inspiration, check out the Markdown files which power the personal demo. The easiest way to publish your new site to the internet is with Netlify.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt    ","tags":null,"title":"Academic Kickstart","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9bde7b2b9f43447e419376962aff7c10","permalink":"https://ben-mlr.github.io/post/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/skills/","section":"post","summary":"","tags":null,"title":"Skills","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a9f5bf28693a200d1a03697c1ff586a3","permalink":"https://ben-mlr.github.io/back/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/back/experience/","section":"back","summary":"","tags":null,"title":"Experience","type":"back"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d298054db7638d33e35f6283cc04d55b","permalink":"https://ben-mlr.github.io/post/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/accomplishments/","section":"post","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"post"},{"authors":null,"categories":null,"content":"SDFSF\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"18d742c8500e3e95a88d95021ee7f3f7","permalink":"https://ben-mlr.github.io/post/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/posts/","section":"post","summary":"SDFSF","tags":null,"title":"Recent Posts","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f0c8b37e465d73f467bf3b490c273cd5","permalink":"https://ben-mlr.github.io/post/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/projects/","section":"post","summary":"","tags":null,"title":"Projects","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"995147a03f8d91f2f66b6d06687a9677","permalink":"https://ben-mlr.github.io/post/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/people/","section":"post","summary":"","tags":null,"title":"People","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"457e61a499a0603b9ba93d7dac5234e7","permalink":"https://ben-mlr.github.io/post/resources/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/resources/","section":"post","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e49c50ff7def1950f9c7f20c7bbf9921","permalink":"https://ben-mlr.github.io/post/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/talks/","section":"post","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7fc74d3109da43174cae54f0a6e0e503","permalink":"https://ben-mlr.github.io/post/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/featured/","section":"post","summary":"","tags":null,"title":"Featured Publications","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e50d1df6746968014eaaa2f617b71d4d","permalink":"https://ben-mlr.github.io/post/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/tags/","section":"post","summary":"","tags":null,"title":"Popular Topics","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7f6dbb1ccf1f831dddabb0ef170679e0","permalink":"https://ben-mlr.github.io/back/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/back/contact/","section":"back","summary":"","tags":null,"title":"Contact","type":"back"},{"authors":["Benjamin Muller"],"categories":null,"content":"","date":1655856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655856000,"objectID":"efd6aa626e35c548e8b2c0d03f2efcf9","permalink":"https://ben-mlr.github.io/talks/institut-pasteur/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talks/institut-pasteur/","section":"talks","summary":"","tags":["Source Themes"],"title":"Institut Pasteur, Imaging and Modeling lab from the Department of Computational Biology Seminar, Camembert and Beyond","type":"talks"},{"authors":["Benjamin Muller"],"categories":null,"content":"","date":1648684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648684800,"objectID":"4c3f63728d6f830c2b62ddb458331ac9","permalink":"https://ben-mlr.github.io/talks/jhu/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talks/jhu/","section":"talks","summary":"","tags":["Source Themes"],"title":"JHU CSLP Seminar, Cross-Lingual Transfer with Multilingual Language Models","type":"talks"},{"authors":["Benjamin Muller"],"categories":null,"content":"","date":1638403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638403200,"objectID":"9b0a24abea63117328754bb44f48246b","permalink":"https://ben-mlr.github.io/talks/gmu/","publishdate":"2020-09-08T00:00:00Z","relpermalink":"/talks/gmu/","section":"talks","summary":"","tags":["Source Themes"],"title":"George Mason Natural Language Processing Group , Virginia, Toward a Cross-Lingual Generative Question Answering System","type":"talks"},{"authors":["Benjamin Muller","Luca Soldaini","Rik Koncel-Kedziorski","Eric Lind","Alessandro Moschitti"],"categories":null,"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"50a75c1f211d181004c85884dba3c082","permalink":"https://ben-mlr.github.io/publication/crossgenqa/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/crossgenqa/","section":"publication","summary":"Open-Retrieval Generative Question Answering (GENQA) is proven to deliver high-quality, natural-sounding answers in English. In this paper, we present the first generalization of the GENQA approach for the multilingual environment. To this end, we present the GEN-TYDIQA dataset, which extends the TyDiQA evaluation data (Clark et al., 2020) with natural-sounding, well-formed answers in Arabic, Bengali, English, Japanese, and Russian. For all these languages, we show that a GENQA sequence-to-sequence-based model outperforms a state-of-the-art Answer Sentence Selection model. We also show that a multilingually-trained model competes with, and in some cases outperforms, its monolingual counterparts. Finally, we show that our system can even compete with strong baselines, even when fed with information from a variety of languages. Essentially, our system is able to answer a question in any language of our language set using information from many languages, making it the first LanguageAgnostic GENQA system","tags":["Source Themes"],"title":"Cross-Lingual GENQA: A Language-Agnostic Generative Question Answering Approach for Open-Domain Question Answering","type":"publication"},{"authors":["Benjamin Muller","Antonios Anastasopoulos","Benoît Sagot","Djamé Seddah"],"categories":null,"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"bc846f9ab68067e8c6f8cc6d513e01b7","permalink":"https://ben-mlr.github.io/publication/unseen-languages/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/unseen-languages/","section":"publication","summary":"Transfer learning based on pretraining language models on a large amount of raw data has become a new norm to reach state-of-the-art performance in NLP. Still, it remains unclear how this approach should be applied for unseen languages that are not covered by any available large-scale multilingual language model and for which only a small amount of raw data is generally available. In this work, by comparing multilingual and monolingual models, we show that such models behave in multiple ways on unseen languages. Some languages greatly benefit from transfer learning and behave similarly to closely related high resource languages whereas others apparently do not. Focusing on the latter, we show that this failure to transfer is largely related to the impact of the script used to write such languages. We show that transliterating those languages significantly improves the potential of large-scale multilingual language models on downstream tasks. This result provides a promising direction towards making these massively multilingual models useful for a new set of unseen languages.","tags":["Source Themes"],"title":"When Being Unseen from mBERT is just the Beginning: Handling New Languages With Multilingual Language Models","type":"publication"},{"authors":["Benjamin Muller","Yanai Elazar","Benoit Sagot","Djamé Seddah"],"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"70d557e11ed85a0ce86116325fc4738a","permalink":"https://ben-mlr.github.io/publication/first-align-then-predict/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/first-align-then-predict/","section":"publication","summary":"","tags":["Source Themes"],"title":"First Align, then Predict: Understanding the Cross-Lingual Ability of Multilingual BERT","type":"publication"},{"authors":["Benjamin Muller"],"categories":null,"content":"","date":1610668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610668800,"objectID":"b9ff3f58cc90e344e20b1ce55b7dabce","permalink":"https://ben-mlr.github.io/talks/itu-copenhagen/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talks/itu-copenhagen/","section":"talks","summary":"","tags":["Source Themes"],"title":"ITU Copenhagen, When Being unseen by mBERT is just the beginning, Handling New Languages With Multilingual Language Models","type":"talks"},{"authors":["Benjamin Muller"],"categories":null,"content":"","date":1599523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599523200,"objectID":"1a230276da2923177e99e7ed3b364b2d","permalink":"https://ben-mlr.github.io/talks/edf/","publishdate":"2020-09-08T00:00:00Z","relpermalink":"/talks/edf/","section":"talks","summary":"","tags":["Source Themes"],"title":"EDF Data Innovation Lab, Paris, CamemBERT: a Tasty French Language Model","type":"talks"},{"authors":["Louis Martin*","Benjamin Muller*","Pedro Javier Ortiz Suárez*","Yoann Dupont","Laurent Romary","Éric Villemonte de la Clergerie","Djamé Seddah","Benoît Sagot"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"f953f82f0cb8b1d1cde8149be608056a","permalink":"https://ben-mlr.github.io/publication/camembert/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/camembert/","section":"publication","summary":"Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models –in all languages except English– very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks.","tags":["Source Themes"],"title":"CamemBERT: a Tasty French Language Model","type":"publication"},{"authors":["Benjamin Muller"],"categories":null,"content":"","date":1575072000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575072000,"objectID":"a8f56f3402c049e8bf813c8b2ae9942f","permalink":"https://ben-mlr.github.io/talks/bar-ilan/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talks/bar-ilan/","section":"talks","summary":"","tags":["Source Themes"],"title":"Bar Ilan University, Tel-Aviv, Transfer Learning on an Unseen North-African Arabic Dialect, December 2019","type":"talks"},{"authors":["Benjamin Muller","Benoit Sagot","Djamé Seddah"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"1ddc3e23a31768cfeda525cc00366fa0","permalink":"https://ben-mlr.github.io/publication/bert-lexnorm/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/bert-lexnorm/","section":"publication","summary":"","tags":["Source Themes"],"title":"Enhancing BERT for Lexical Normalization","type":"publication"},{"authors":["Benjamin Muller","Benoît Sagot","Djamé Seddah"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"504a937f5902408c5a9c86d446d769f0","permalink":"https://ben-mlr.github.io/publication/narabizi-adaptation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/narabizi-adaptation/","section":"publication","summary":"Language model pretrained representation are now ubiquitous in Natural Language Processing. In this work, we present some first results in adapting those models to Out-of-Domain textual data. Using Part-of-Speech tagging as our case study, we analyze the ability of BERT to model a complex North-African Dialect NArabizi.","tags":["Source Themes"],"title":"Unsupervised Learning for Handling Code-Mixed Data: A Case Study on POS Tagging of North-African Arabizi Dialect","type":"publication"},{"authors":null,"categories":null,"content":"September 2019\n Emotion Detection with Neural Personal Discrimination presented by Gaël Guibon [slides] [paper]  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c6625328e7b2e36b114847f299065f54","permalink":"https://ben-mlr.github.io/resources/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resources/","section":"","summary":"September 2019\n Emotion Detection with Neural Personal Discrimination presented by Gaël Guibon [slides] [paper]  ","tags":null,"title":"ALMANACH Study Group","type":"page"}]